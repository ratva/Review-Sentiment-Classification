{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model as sklm\n",
    "import sklearn.pipeline\n",
    "import sklearn.model_selection as skms\n",
    "import sklearn.feature_selection \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import nltk\n",
    "\n",
    "# Import our filess\n",
    "from load_train_data import load_data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "website_list, review_list, rating_list = load_data('x_train.csv', 'y_train.csv')\n",
    "\n",
    "numReviewsTotal = len(website_list)\n",
    "\n",
    "random_state = np.random.RandomState(0)\n",
    "dataZip = list(zip(website_list, review_list, rating_list))\n",
    "random_state.shuffle(dataZip)\n",
    "website_list, review_list, rating_list = zip(*dataZip)\n",
    "\n",
    "numReviewsTrain = int(numReviewsTotal * 0.8)\n",
    "\n",
    "website_TR = website_list[:numReviewsTrain]\n",
    "review_TR = review_list[:numReviewsTrain]\n",
    "rating_TR = rating_list[:numReviewsTrain]\n",
    "\n",
    "website_TE = website_list[numReviewsTrain:]\n",
    "review_TE = review_list[numReviewsTrain:]\n",
    "rating_TE = rating_list[numReviewsTrain:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = sklm.LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "distributions = dict(C=np.logspace(-9,6,31), penalty = ['l2', 'l1'])\n",
    "\n",
    "#Pipeline starts!\n",
    "my_bow_classifier_pipeline1 = sklearn.pipeline.Pipeline([\n",
    "    ('my_bow_feature_extractor', CountVectorizer(min_df=1, max_df=1.0, ngram_range=(1,1))),\n",
    "    ('cross validation', skms.RandomizedSearchCV(logistic, distributions, n_iter=100, cv=10, verbose=0, random_state=0, error_score='raise', return_train_score=True))\n",
    "])\n",
    "\n",
    "my_bow_classifier_pipeline1.fit(review_TR, rating_TR)\n",
    "my_bow_classifier_pipeline1.predict(review_TR)\n",
    "my_bow_classifier_pipeline1.score(review_TR, rating_TR)\n",
    "probs1TR = my_bow_classifier_pipeline1.predict_proba(review_TR)\n",
    "probs1TE = my_bow_classifier_pipeline1.predict_proba(review_TE)\n",
    "\n",
    "#Pipeline starts!\n",
    "my_bow_classifier_pipeline2 = sklearn.pipeline.Pipeline([\n",
    "    ('my_bow_feature_extractor', CountVectorizer(min_df=1, max_df=1.0, ngram_range=(1,2))),\n",
    "    ('cross validation', skms.RandomizedSearchCV(logistic, distributions, n_iter=100, cv=10, verbose=0, random_state=0, error_score='raise', return_train_score=True))\n",
    "])\n",
    "\n",
    "my_bow_classifier_pipeline2.fit(review_TR, rating_TR)\n",
    "my_bow_classifier_pipeline2.predict(review_TR)\n",
    "my_bow_classifier_pipeline2.score(review_TR, rating_TR)\n",
    "probs2TR = my_bow_classifier_pipeline2.predict_proba(review_TR)\n",
    "probs2TE = my_bow_classifier_pipeline2.predict_proba(review_TE)\n",
    "\n",
    "#Pipeline starts!\n",
    "my_bow_classifier_pipeline3 = sklearn.pipeline.Pipeline([\n",
    "    ('my_bow_feature_extractor', CountVectorizer(min_df=1, max_df=1.0, ngram_range=(1,3))),\n",
    "    ('cross validation', skms.RandomizedSearchCV(logistic, distributions, n_iter=100, cv=10, verbose=0, random_state=0, error_score='raise', return_train_score=True))\n",
    "])\n",
    "\n",
    "my_bow_classifier_pipeline3.fit(review_TR, rating_TR)\n",
    "my_bow_classifier_pipeline3.predict(review_TR)\n",
    "my_bow_classifier_pipeline3.score(review_TR, rating_TR)\n",
    "probs3TR = my_bow_classifier_pipeline3.predict_proba(review_TR)\n",
    "probs3TE = my_bow_classifier_pipeline3.predict_proba(review_TE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1 = my_bow_classifier_pipeline1['cross validation'].best_estimator_.coef_\n",
    "\n",
    "#getting CountVectorizer dictionary\n",
    "dictionary1 = my_bow_classifier_pipeline1['my_bow_feature_extractor'].vocabulary_\n",
    "\n",
    "print(my_bow_classifier_pipeline1['cross validation'].best_params_)\n",
    "\n",
    "acc1TR = roc_auc_score(rating_TR, probs1TR[:,1])\n",
    "print(\"Training accuracy: %.3f\" % acc1TR)\n",
    "acc1TE = roc_auc_score(rating_TE, probs1TE[:,1])\n",
    "print(\"Training accuracy: %.3f\" % acc1TE)\n",
    "\n",
    "\n",
    "weights2 = my_bow_classifier_pipeline2['cross validation'].best_estimator_.coef_\n",
    "\n",
    "#getting CountVectorizer dictionary\n",
    "dictionary2 = my_bow_classifier_pipeline2['my_bow_feature_extractor'].vocabulary_\n",
    "\n",
    "print(my_bow_classifier_pipeline2['cross validation'].best_params_)\n",
    "\n",
    "acc2TR = roc_auc_score(rating_TR, probs2TR[:,1])\n",
    "print(\"Training accuracy: %.3f\" % acc2TR)\n",
    "acc2TE = roc_auc_score(rating_TE, probs2TE[:,1])\n",
    "print(\"Training accuracy: %.3f\" % acc2TE)\n",
    "\n",
    "\n",
    "\n",
    "weights3 = my_bow_classifier_pipeline3['cross validation'].best_estimator_.coef_\n",
    "\n",
    "#getting CountVectorizer dictionary\n",
    "dictionary3 = my_bow_classifier_pipeline3['my_bow_feature_extractor'].vocabulary_\n",
    "\n",
    "print(my_bow_classifier_pipeline3['cross validation'].best_params_)\n",
    "\n",
    "acc3TR = roc_auc_score(rating_TR, probs3TR[:,1])\n",
    "print(\"Training accuracy: %.3f\" % acc3TR)\n",
    "acc3TE = roc_auc_score(rating_TE, probs3TE[:,1])\n",
    "print(\"Training accuracy: %.3f\" % acc3TE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results - random state isn't currently consistent.\n",
    "Evaluation of 1, 2 and 3-ngram performance applied to a random 80% of the training data, evaluated against that after 10 fold CV and the 20% heldout test data.\n",
    "\n",
    "```python\n",
    "{'penalty': 'l2', 'C': 31.622776601683793}\n",
    "Training accuracy: 1.000\n",
    "Training accuracy: 0.858\n",
    "{'penalty': 'l1', 'C': 31622.776601683792}\n",
    "Training accuracy: 1.000\n",
    "Training accuracy: 0.885\n",
    "{'penalty': 'l1', 'C': 3162.2776601683795}\n",
    "Training accuracy: 1.000\n",
    "Training accuracy: 0.884\n",
    "```\n",
    "\n",
    "\n",
    "Attempt 2:\n",
    "```python\n",
    "{'penalty': 'l2', 'C': 31.622776601683793}\n",
    "Training accuracy: 1.000\n",
    "Training accuracy: 0.858\n",
    "{'penalty': 'l1', 'C': 3162.2776601683795}\n",
    "Training accuracy: 1.000\n",
    "Training accuracy: 0.888\n",
    "{'penalty': 'l1', 'C': 1000.0}\n",
    "Training accuracy: 1.000\n",
    "Training accuracy: 0.890\n",
    "```\n",
    "\n",
    "Evaluation of 1, 2 and 3-ngram performance applied to a random 80% of the training data, evaluated against that after 5 fold CV and the 20% heldout test data.\n",
    "\n",
    "```python\n",
    "{'penalty': 'l2', 'C': 31.622776601683793}\n",
    "Training accuracy: 1.000\n",
    "Training accuracy: 0.858\n",
    "{'penalty': 'l1', 'C': 10000.0}\n",
    "Training accuracy: 1.000\n",
    "Training accuracy: 0.883\n",
    "{'penalty': 'l1', 'C': 1000.0}\n",
    "Training accuracy: 1.000\n",
    "Training accuracy: 0.885\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_te_data = 'x_test.csv'\n",
    "data_dir = 'data_reviews'\n",
    "x_te_df = pd.read_csv(os.path.join(data_dir, x_te_data))\n",
    "te_website_list = x_te_df['website_name'].values.tolist()\n",
    "te_text_list = x_te_df['text'].values.tolist()\n",
    "\n",
    "\n",
    "np.savetxt('q2_1ngram.txt', probs1TE, fmt='%s')\n",
    "np.savetxt('q2_2ngram.txt', probs2TE, fmt='%s')\n",
    "np.savetxt('q2_3ngram.txt', probs3TE, fmt='%s')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
