{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model as sklm\n",
    "import sklearn.pipeline\n",
    "import sklearn.model_selection as skms\n",
    "import sklearn.feature_selection \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Import our filess\n",
    "from load_train_data import load_data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data from csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "website_list, review_list, rating_list = load_data('x_train.csv', 'y_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROBLEM 1:\n",
    "Defining pipeline for predicting and fitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leigh\\micromamba\\envs\\cs135_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 62 is smaller than n_iter=100. Running 62 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "logistic = sklm.LogisticRegression(solver='liblinear', max_iter=100)\n",
    "distributions = dict(C=np.logspace(-9,6,31), penalty = ['l2', 'l1'])\n",
    "\n",
    "#Pipeline starts!\n",
    "my_bow_classifier_pipeline = sklearn.pipeline.Pipeline([\n",
    "    ('my_bow_feature_extractor', CountVectorizer(min_df=1, max_df=1.0, ngram_range=(1,1))),\n",
    "    ('cross validation', skms.RandomizedSearchCV(logistic, distributions, n_iter=100, cv=10, verbose=0, random_state=0, error_score='raise', return_train_score=True))\n",
    "])\n",
    "\n",
    "my_bow_classifier_pipeline.fit(review_list, rating_list)\n",
    "my_bow_classifier_pipeline.predict(review_list)\n",
    "my_bow_classifier_pipeline.score(review_list, rating_list)\n",
    "probs = my_bow_classifier_pipeline.predict_proba(review_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l2', 'C': 1.0}\n",
      "Training accuracy: 0.994\n"
     ]
    }
   ],
   "source": [
    "weights = my_bow_classifier_pipeline['cross validation'].best_estimator_.coef_\n",
    "\n",
    "#getting CountVectorizer dictionary\n",
    "dictionary = my_bow_classifier_pipeline['my_bow_feature_extractor'].vocabulary_\n",
    "\n",
    "print(my_bow_classifier_pipeline['cross validation'].best_params_)\n",
    "\n",
    "acc = roc_auc_score(rating_list, probs[:, 1])\n",
    "print(\"Training accuracy: %.3f\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting 0.89106 for Gradescope submission!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53394516 0.4760095  0.10120415 0.05030966 0.32383209 0.05893481\n",
      " 0.04369099 0.20793626 0.23058191 0.47927785 0.40941855 0.61267748\n",
      " 0.06951167 0.11076701 0.25786707 0.05449893 0.00735609 0.14522679\n",
      " 0.38067303 0.63967442 0.44020526 0.46111084 0.26931365 0.24878015\n",
      " 0.42375413 0.39155014 0.21319605 0.47269212 0.20008731 0.25979086\n",
      " 0.54861097 0.22845893 0.38094212 0.00490693 0.33457314 0.35640788\n",
      " 0.26650577 0.14854029 0.41721891 0.44249259 0.09374761 0.09317715\n",
      " 0.51424534 0.21361626 0.19960758 0.03375936 0.23507921 0.05202372\n",
      " 0.01614569 0.20008731 0.12203483 0.15485532 0.88203374 0.3400139\n",
      " 0.32262402 0.22818082 0.15380822 0.04289929 0.66804447 0.10089488\n",
      " 0.46964958 0.1109564  0.13282705 0.09016455 0.05959207 0.05211388\n",
      " 0.0391277  0.61634297 0.06944637 0.51318222 0.0735873  0.44880093\n",
      " 0.06685663 0.01573909 0.28335287 0.33613814 0.24898975 0.03503635\n",
      " 0.54091134 0.1640306  0.20943812 0.0224517  0.15591127 0.3041604\n",
      " 0.0098755  0.31128656 0.13127829 0.05961275 0.29768897 0.04814806\n",
      " 0.37382048 0.16165668 0.47524251 0.10721396 0.31608122 0.25454208\n",
      " 0.33594242 0.30395792 0.06582152 0.28251027 0.98691252 0.61622857\n",
      " 0.5306234  0.91609567 0.49711699 0.97165066 0.92534926 0.95916157\n",
      " 0.00105354 0.17999325 0.93637193 0.33747342 0.92109104 0.30575051\n",
      " 0.8090425  0.67246677 0.79569272 0.94497437 0.81693638 0.50574701\n",
      " 0.05849875 0.75762667 0.84200025 0.93814081 0.93084321 0.97123272\n",
      " 0.81408588 0.77733728 0.98187762 0.61707262 0.99900118 0.8387666\n",
      " 0.9635485  0.99085698 0.99458954 0.54889871 0.12413176 0.91346184\n",
      " 0.76092715 0.97921222 0.95347899 0.11323978 0.82444103 0.93264274\n",
      " 0.80787213 0.86499761 0.04585718 0.14417362 0.98008208 0.9181965\n",
      " 0.99992091 0.96311367 0.76104944 0.9016757  0.63713883 0.78419634\n",
      " 0.80799353 0.52394307 0.94335002 0.60059929 0.51934526 0.68957791\n",
      " 0.65886147 0.95461933 0.9473212  0.59227029 0.86244205 0.5439488\n",
      " 0.59055484 0.33663088 0.43364754 0.49252189 0.67121922 0.64722954\n",
      " 0.9111418  0.99267635 0.65808231 0.4582505  0.97561182 0.69492469\n",
      " 0.86246251 0.08107991 0.81886581 0.92845049 0.78334378 0.95026491\n",
      " 0.86944468 0.96513453 0.37242736 0.84672121 0.9413744  0.74117942\n",
      " 0.70591899 0.98717185 0.84151495 0.90852621 0.53186618 0.32040813\n",
      " 0.46044209 0.91246015 0.09817775 0.35918256 0.14649811 0.61706915\n",
      " 0.01738974 0.38412232 0.0679761  0.00176447 0.24440584 0.69309312\n",
      " 0.07549004 0.042916   0.28277873 0.491379   0.59159764 0.3163923\n",
      " 0.23753248 0.26745136 0.4084494  0.04192203 0.03348028 0.15692735\n",
      " 0.34878208 0.22552486 0.03478765 0.01565365 0.0277726  0.45319631\n",
      " 0.27964659 0.40841153 0.03028947 0.18440277 0.84442705 0.48330572\n",
      " 0.4055094  0.1557527  0.05966702 0.46327771 0.46373597 0.05963524\n",
      " 0.15537952 0.09767814 0.48496429 0.00724022 0.80645842 0.01394111\n",
      " 0.12462685 0.00248457 0.06555959 0.35514268 0.42486899 0.5905698\n",
      " 0.72090413 0.05263173 0.57013349 0.14872794 0.45907801 0.15143704\n",
      " 0.24931454 0.44949114 0.35749007 0.14867871 0.07882315 0.07400337\n",
      " 0.15821112 0.27975983 0.22721514 0.17697656 0.0335754  0.1339938\n",
      " 0.07013533 0.09398457 0.55959899 0.44579114 0.22769206 0.13749198\n",
      " 0.43992218 0.33908418 0.41411879 0.16280361 0.08074198 0.28599002\n",
      " 0.6802466  0.29699091 0.06467248 0.03405427 0.69446843 0.22781197\n",
      " 0.27552087 0.64379377 0.26495235 0.2316063  0.05382305 0.00438243\n",
      " 0.44379527 0.01189763 0.58982768 0.40515026 0.10935594 0.69228117\n",
      " 0.70637586 0.42702996 0.80291861 0.84345846 0.54639637 0.98054817\n",
      " 0.42877734 0.26818136 0.25973373 0.46011653 0.69306461 0.63009303\n",
      " 0.41727428 0.22891344 0.32430636 0.77883818 0.12880931 0.90076048\n",
      " 0.70670668 0.86544275 0.92497568 0.99993891 0.8567892  0.57711266\n",
      " 0.57941282 0.82153244 0.9998286  0.68947945 0.9247651  0.62453145\n",
      " 0.99831037 0.56037584 0.54416747 0.12134919 0.4840564  0.92621803\n",
      " 0.95157116 0.72762646 0.66267297 0.63798337 0.41840948 0.10262499\n",
      " 0.38590691 0.39596567 0.95253021 0.73897936 0.62643973 0.75275339\n",
      " 0.12020363 0.78080251 0.65981398 0.21281884 0.89143722 0.7620744\n",
      " 0.77469305 0.44621312 0.94332014 0.93243407 0.96726002 0.99687244\n",
      " 0.5182097  0.92671298 0.34610837 0.51481953 0.76843357 0.62516932\n",
      " 0.92148343 0.99021943 0.49111531 0.88280498 0.42868558 0.82645342\n",
      " 0.49470532 0.92313201 0.50923041 0.95904997 0.94087931 0.55673064\n",
      " 0.66874074 0.65979311 0.74040427 0.91910523 0.44357382 0.99202693\n",
      " 0.69606814 0.92799746 0.51251355 0.35960424 0.90336849 0.76868468\n",
      " 0.47537437 0.40552494 0.98006123 0.03825436 0.20922141 0.96470633\n",
      " 0.47413065 0.76444799 0.23492879 0.86484184 0.09638096 0.22718945\n",
      " 0.00305478 0.36718177 0.37953581 0.13764791 0.088613   0.05695792\n",
      " 0.08576839 0.47150097 0.57353225 0.05045467 0.0951029  0.30636328\n",
      " 0.44360042 0.14894699 0.31833212 0.19522111 0.35679839 0.30573087\n",
      " 0.31899629 0.25666974 0.21092054 0.03705101 0.59776445 0.4787242\n",
      " 0.54177363 0.39373474 0.43979119 0.52661053 0.10096736 0.36325322\n",
      " 0.01120503 0.29857711 0.28785855 0.17383531 0.44099048 0.04056139\n",
      " 0.06454118 0.25699469 0.91091706 0.50496581 0.0579989  0.1065851\n",
      " 0.1021945  0.08032031 0.52268032 0.01641888 0.62720044 0.59393908\n",
      " 0.33170188 0.23474693 0.34414998 0.33012372 0.12764755 0.61118685\n",
      " 0.44242928 0.39037065 0.46270487 0.39432433 0.10021249 0.13836114\n",
      " 0.49113778 0.23995964 0.11536301 0.33776668 0.32188499 0.44360983\n",
      " 0.41680758 0.7626602  0.32949828 0.37865384 0.37381904 0.11845472\n",
      " 0.24270189 0.6636288  0.23181577 0.35145399 0.13889992 0.31471487\n",
      " 0.02930466 0.4014867  0.19518968 0.27901532 0.28820072 0.10323059\n",
      " 0.00351308 0.37620952 0.57053653 0.04997427 0.21454535 0.56721347\n",
      " 0.10366156 0.43403735 0.35969325 0.38570768 0.07829344 0.13662052\n",
      " 0.24213807 0.23901963 0.9902878  0.80517578 0.85985442 0.28566268\n",
      " 0.71994166 0.71073762 0.94474757 0.76551686 0.94924052 0.42389749\n",
      " 0.64371205 0.92934134 0.73672388 0.67299524 0.50455726 0.87162644\n",
      " 0.85274314 0.89469721 0.74748141 0.81258502 0.79152852 0.83804141\n",
      " 0.80919725 0.09143197 0.60939085 0.98200561 0.13678509 0.7303765\n",
      " 0.76284831 0.99904568 0.47909004 0.93416636 0.45028233 0.94058262\n",
      " 0.54801593 0.40788504 0.55097954 0.33756883 0.73671492 0.970689\n",
      " 0.46733013 0.5617794  0.96129079 0.8746202  0.87834689 0.75616489\n",
      " 0.94186    0.55410086 0.97719357 0.9980749  0.68927526 0.0234857\n",
      " 0.71947803 0.94250177 0.80806586 0.96413751 0.65185628 0.78873927\n",
      " 0.60177606 0.57114907 0.71628705 0.84318153 0.99637417 0.99468515\n",
      " 0.60917832 0.42063352 0.31473062 0.88050019 0.8465643  0.55392834\n",
      " 0.91751036 0.69923502 0.25436655 0.28782272 0.69206424 0.29385608\n",
      " 0.8510565  0.84323577 0.76828915 0.81651651 0.9033301  0.32335725\n",
      " 0.96995918 0.53494691 0.86816174 0.96172416 0.85335565 0.90831965\n",
      " 0.93952719 0.45060771 0.24782863 0.50260825 0.77907994 0.33239052\n",
      " 0.85154056 0.96043123 0.74510756 0.84251067 0.99799546 0.81137952]\n"
     ]
    }
   ],
   "source": [
    "x_te_data = 'x_test.csv'\n",
    "data_dir = 'data_reviews'\n",
    "x_te_df = pd.read_csv(os.path.join(data_dir, x_te_data))\n",
    "te_website_list = x_te_df['website_name'].values.tolist()\n",
    "te_text_list = x_te_df['text'].values.tolist()\n",
    "\n",
    "probs = my_bow_classifier_pipeline.predict_proba(te_text_list)[:, 1]\n",
    "print(probs)\n",
    "\n",
    "np.savetxt('q1.txt', probs, fmt='%s')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import punkt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "#punkt and stopwords downloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing words again, but using nltk this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oh', 'forgot', 'also', 'mention', 'weird', 'color', 'effect', 'phone', 'one', \"n't\", 'work', 'either', 'waste', '13', 'bucks', 'product', 'useless', 'since', 'enough', 'charging', 'current', 'charge', '2', 'cellphones', 'planning', 'use', 'none', 'three', 'sizes', 'sent', 'headset', 'would', 'stay', 'ears', 'worst', 'customer', 'service', 'ngage', 'still', 'lacking', 'earbuds', 'always', 'cuts', 'makes', 'beep', 'beep', 'beep', 'sound', 'says', 'signal', 'failed', 'disappointing', 'thing', 'speakerphone', 'disappointed', 'accessoryone', 'basically', 'service', 'bad', 'bad', 'choice', 'thing', 'disappoint', 'infra', 'red', 'port', 'irda', 'horrible', 'switch', '3', 'times', 'feels', 'poorly', 'constructed', 'menus', 'difficult', 'navigate', 'buttons', 'recessed', 'difficult', 'push', \"n't\", 'make', 'mistake', 'muddy', 'low', 'quality', 'sound', 'casing', 'around', 'wire', \"'s\", 'insert', 'poorly', 'super', 'glued', 'slid', 'advise', 'everyone', 'fooled']\n"
     ]
    }
   ],
   "source": [
    "tokenz = list()\n",
    "punc = ['.', '..', '...', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}','%']\n",
    "\n",
    "for reviewIdx in range(len(review_list)):\n",
    "    cur_token = review_list[reviewIdx] # cur_token is 1 review\n",
    "    for word in cur_token:\n",
    "        cur_word = word_tokenize(word)\n",
    "        if cur_word not in stopwords.words('english'):\n",
    "            tokenz.append(word.lower())\n",
    "\n",
    "for word in tokenz:\n",
    "    if word in punc:\n",
    "        tokenz.remove(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oh', 'forgot', 'also', 'mention', 'weird', 'color', 'effect', 'phone', 'one', \"n't\", 'work', 'either', 'waste', '13', 'bucks', 'product', 'useless', 'since', 'enough', 'charging', 'current', 'charge', '2', 'cellphones', 'planning', 'use', 'none', 'three', 'sizes', 'sent', 'headset', 'would', 'stay', 'ears', 'worst', 'customer', 'service', 'ngage', 'still', 'lacking', 'earbuds', 'always', 'cuts', 'makes', 'beep', 'beep', 'beep', 'sound', 'says', 'signal', 'failed', 'disappointing', 'thing', 'speakerphone', 'disappointed', 'accessoryone', 'basically', 'service', 'bad', 'bad', 'choice', 'thing', 'disappoint', 'infra', 'red', 'port', 'irda', 'horrible', 'switch', '3', 'times', 'feels', 'poorly', 'constructed', 'menus', 'difficult', 'navigate', 'buttons', 'recessed', 'difficult', 'push', \"n't\", 'make', 'mistake', 'muddy', 'low', 'quality', 'sound', 'casing', 'around', 'wire', \"'s\", 'insert', 'poorly', 'super', 'glued', 'slid', 'advise', 'everyone', 'fooled']\n"
     ]
    }
   ],
   "source": [
    "print(tokenz[0:100])\n",
    "#print(stopwords.words('english')[0:10])\n",
    "\n",
    "#print(cur_word in stopwords.words('english'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
