{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from load_train_data import load_data \n",
    "#from clean_data import tokenize_text, create_word_list, make_feature_vector\n",
    "import sklearn.model_selection\n",
    "import sklearn.feature_selection\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tokenize_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\avtar\\OneDrive - Tufts\\Tufts CS\\CS135 Intro to ML\\projectA\\CS135-Project-A\\tests.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/avtar/OneDrive%20-%20Tufts/Tufts%20CS/CS135%20Intro%20to%20ML/projectA/CS135-Project-A/tests.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m website_list, vocab_list, rating_list \u001b[39m=\u001b[39m load_data(\u001b[39m'\u001b[39m\u001b[39mx_train.csv\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39my_train.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/avtar/OneDrive%20-%20Tufts/Tufts%20CS/CS135%20Intro%20to%20ML/projectA/CS135-Project-A/tests.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/avtar/OneDrive%20-%20Tufts/Tufts%20CS/CS135%20Intro%20to%20ML/projectA/CS135-Project-A/tests.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m tokens \u001b[39m=\u001b[39m tokenize_text(vocab_list)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/avtar/OneDrive%20-%20Tufts/Tufts%20CS/CS135%20Intro%20to%20ML/projectA/CS135-Project-A/tests.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m word_count_dict \u001b[39m=\u001b[39m create_word_list(tokens)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/avtar/OneDrive%20-%20Tufts/Tufts%20CS/CS135%20Intro%20to%20ML/projectA/CS135-Project-A/tests.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m#threshold of words that are infrequent is 3 right now. Change later(?)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenize_text' is not defined"
     ]
    }
   ],
   "source": [
    "print(0)\n",
    "\n",
    "website_list, vocab_list, rating_list = load_data('x_train.csv', 'y_train.csv')\n",
    "\n",
    "print(1)\n",
    "tokens = tokenize_text(vocab_list)\n",
    "\n",
    "word_count_dict = create_word_list(tokens)\n",
    "\n",
    "#threshold of words that are infrequent is 3 right now. Change later(?)\n",
    "sorted_tokens = list(sorted(word_count_dict, key=word_count_dict.get, reverse=True))\n",
    "# vocab_list = [w for w in sorted_tokens if word_count_dict[w] >= 3]\n",
    "print(sorted_tokens)\n",
    "print(rating_list)\n",
    "a_review = 'It feels poorly constructed, the menus are difficult to navigate, and the buttons are so recessed that it is difficult to push them.'\n",
    "make_feature_vector(a_review, word_count_dict)\n",
    "\n",
    "pos_review = 0\n",
    "if rating_list == 1:\n",
    "    pos_review += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_cleaner = CountVectorizer(ngram_range=(1,1), min_df=1, max_df=1.0, tokenizer=True, vocabulary=None)\n",
    "bow_cleaner.fit(rating_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to run a unit test to run on the analysis functions, but didn't get it working yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "from analysis import cross_validation, clean_words\n",
    "\n",
    "class TestAnalysis(unittest.TestCase):\n",
    "    \n",
    "    def test_cross_validation(self):\n",
    "        # Test that test_ids_fold and train_ids_fold are lists\n",
    "        x_NF = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "        y_N = np.array([0, 1, 0, 1])\n",
    "        n_folds = 2\n",
    "        test_ids_fold, train_ids_fold = cross_validation(x_NF, y_N, n_folds)\n",
    "        self.assertIsInstance(test_ids_fold, list)\n",
    "        self.assertIsInstance(train_ids_fold, list)\n",
    "        \n",
    "        # Test that test_ids_fold and train_ids_fold have the correct length\n",
    "        self.assertEqual(len(test_ids_fold), n_folds)\n",
    "        self.assertEqual(len(train_ids_fold), n_folds)\n",
    "        \n",
    "        # Test that test_ids_fold and train_ids_fold contain the correct indices\n",
    "        for i in range(n_folds):\n",
    "            test_ids = test_ids_fold[i]\n",
    "            train_ids = train_ids_fold[i]\n",
    "            self.assertEqual(len(test_ids), len(train_ids))\n",
    "            self.assertEqual(set(test_ids).union(set(train_ids)), set(range(len(x_NF))))\n",
    "    \n",
    "    def test_clean_words(self):\n",
    "        # Test that y_hat is a sparse matrix\n",
    "        web_list = ['www.example.com', 'www.example.com', 'www.example.com']\n",
    "        reviews_list = ['This is a great product', 'This product is terrible', 'I love this product']\n",
    "        stars_list = [5, 1, 5]\n",
    "        n_folds = 2\n",
    "        y_hat = clean_words(web_list, reviews_list, stars_list, n_folds)\n",
    "        self.assertIsInstance(y_hat, scipy.sparse.csr.csr_matrix)\n",
    "        \n",
    "        # Test that y_hat has the correct shape\n",
    "        self.assertEqual(y_hat.shape, (3, len(reviews_list)))\n",
    "        \n",
    "        # Test that y_hat contains the correct values\n",
    "        expected_y_hat = np.array([[1, 0, 1], [0, 1, 0], [1, 0, 1]])\n",
    "        np.testing.assert_array_equal(y_hat.toarray(), expected_y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_clean_words (__main__.TestAnalysis) ... ERROR\n",
      "test_cross_validation (__main__.TestAnalysis) ... ERROR\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_clean_words (__main__.TestAnalysis)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\avtar\\AppData\\Local\\Temp\\ipykernel_33868\\4049955421.py\", line 33, in test_clean_words\n",
      "    y_hat = clean_words(web_list, reviews_list, stars_list, n_folds)\n",
      "  File \"c:\\Users\\avtar\\OneDrive - Tufts\\Tufts CS\\CS135 Intro to ML\\projectA\\CS135-Project-A\\analysis.py\", line 44, in clean_words\n",
      "    x_N = bow_classifier.fit_transform(reviews_list)\n",
      "  File \"c:\\Users\\avtar\\micromambaenv\\envs\\cs135_env\\lib\\site-packages\\sklearn\\pipeline.py\", line 437, in fit_transform\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"c:\\Users\\avtar\\micromambaenv\\envs\\cs135_env\\lib\\site-packages\\sklearn\\pipeline.py\", line 339, in _fit\n",
      "    self._validate_steps()\n",
      "  File \"c:\\Users\\avtar\\micromambaenv\\envs\\cs135_env\\lib\\site-packages\\sklearn\\pipeline.py\", line 230, in _validate_steps\n",
      "    raise TypeError(\n",
      "TypeError: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'LogisticRegression()' (type <class 'sklearn.linear_model._logistic.LogisticRegression'>) doesn't\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_cross_validation (__main__.TestAnalysis)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\avtar\\AppData\\Local\\Temp\\ipykernel_33868\\4049955421.py\", line 12, in test_cross_validation\n",
      "    test_ids_fold, train_ids_fold = cross_validation(x_NF, y_N, n_folds)\n",
      "TypeError: cannot unpack non-iterable NoneType object\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.009s\n",
      "\n",
      "FAILED (errors=2)\n"
     ]
    }
   ],
   "source": [
    "test_analysis = TestAnalysis()\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromModule(test_analysis)\n",
    "\n",
    "test_result = unittest.TextTestRunner(verbosity=2).run(suite)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading example from online to see how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 2.195254015709299, 'penalty': 'l1'}\n",
      "[0 1 2]\n",
      "LogisticRegression(C=2.195254015709299, max_iter=200, penalty='l1',\n",
      "                   random_state=0, solver='saga', tol=0.01)\n",
      "{'mean_fit_time': array([0.00190678, 0.00200033, 0.00348792, 0.00205584, 0.00140133,\n",
      "       0.00119977, 0.00159998, 0.00120168, 0.00130358, 0.00120049]), 'std_fit_time': array([0.00019825, 0.0006312 , 0.00133834, 0.00119523, 0.00080149,\n",
      "       0.00040004, 0.00048965, 0.00039958, 0.00040223, 0.00040112]), 'mean_score_time': array([0.00046244, 0.00059938, 0.00088792, 0.00019841, 0.0003983 ,\n",
      "       0.        , 0.        , 0.00040092, 0.        , 0.00059996]), 'std_score_time': array([0.00057523, 0.0004894 , 0.00047172, 0.00039682, 0.00048782,\n",
      "       0.        , 0.        , 0.00049103, 0.        , 0.00048986]), 'param_C': masked_array(data=[2.195254015709299, 3.3770629943240693,\n",
      "                   2.1795327319875875, 2.4942547871438894,\n",
      "                   1.75034884505077, 0.22685190926977272,\n",
      "                   1.5337660753031108, 3.2486749151019727,\n",
      "                   2.2721782443757292, 3.34431505414951],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_penalty': masked_array(data=['l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l1',\n",
      "                   'l2'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 2.195254015709299, 'penalty': 'l1'}, {'C': 3.3770629943240693, 'penalty': 'l1'}, {'C': 2.1795327319875875, 'penalty': 'l1'}, {'C': 2.4942547871438894, 'penalty': 'l2'}, {'C': 1.75034884505077, 'penalty': 'l2'}, {'C': 0.22685190926977272, 'penalty': 'l2'}, {'C': 1.5337660753031108, 'penalty': 'l2'}, {'C': 3.2486749151019727, 'penalty': 'l2'}, {'C': 2.2721782443757292, 'penalty': 'l1'}, {'C': 3.34431505414951, 'penalty': 'l2'}], 'split0_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'split1_test_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       0.96666667, 1.        , 1.        , 1.        , 1.        ]), 'split2_test_score': array([0.96666667, 0.96666667, 0.96666667, 0.96666667, 0.96666667,\n",
      "       0.93333333, 0.96666667, 0.96666667, 0.96666667, 0.96666667]), 'split3_test_score': array([0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
      "       0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333]), 'split4_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'mean_test_score': array([0.98      , 0.98      , 0.98      , 0.98      , 0.98      ,\n",
      "       0.96666667, 0.98      , 0.98      , 0.98      , 0.98      ]), 'std_test_score': array([0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667,\n",
      "       0.02981424, 0.02666667, 0.02666667, 0.02666667, 0.02666667]), 'rank_test_score': array([ 1,  1,  1,  1,  1, 10,  1,  1,  1,  1])}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import sklearn.model_selection as skms\n",
    "import sklearn.linear_model as sklm\n",
    "from scipy.stats import uniform\n",
    "\n",
    "iris = load_iris()\n",
    "logistic = sklm.LogisticRegression(solver='saga', tol=1e-2, max_iter=200,random_state=0)\n",
    "distributions = dict(C=uniform(loc=0, scale=4), penalty=['l2', 'l1'])\n",
    "clf = skms.RandomizedSearchCV(logistic, distributions, random_state=0)\n",
    "search = clf.fit(iris.data, iris.target)\n",
    "search.best_params_\n",
    "print(search.best_params_)\n",
    "print(search.classes_)\n",
    "print(search.best_estimator_)\n",
    "print(search.cv_results_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
