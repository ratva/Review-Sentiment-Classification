{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model as sklm\n",
    "import sklearn.pipeline\n",
    "import sklearn.model_selection as skms\n",
    "import sklearn.feature_selection \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Import our filess\n",
    "from load_train_data import load_data \n",
    "from clean_data import tokenize_text, create_word_list, create_dict, make_feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "website_list, review_list, rating_list = load_data('x_train.csv', 'y_train.csv')\n",
    "\n",
    "tokens = tokenize_text(review_list) \n",
    "\n",
    "word_count_dict = create_word_list(tokens) # dictionary of word counts\n",
    "sorted_tokens = list(sorted(word_count_dict, key=word_count_dict.get, reverse=True))\n",
    "\n",
    "# clean up the data INSTEAD of tokens = tokenize_text(review_list)\n",
    "vectorizer = CountVectorizer(stop_words = 'english', ngram_range=(1,1), min_df=3, max_df=0.08, binary=False) #filter out words over 0.08 occurence\n",
    "# vectorizer = CountVectorizer(analyzer = 'word',tokenizer=lambda txt: txt.split(),token_pattern = str,ngram_range=(1,1), min_df=0.0, max_df=1.0, binary=False)\n",
    "\n",
    "vectorizer.build_preprocessor()\n",
    "vectorizer.build_tokenizer()\n",
    "X = vectorizer.fit(review_list, rating_list) \n",
    "\n",
    "# Save output to text file\n",
    "with open('wordFreq.txt', 'w') as f:\n",
    "    f.write(str(word_count_dict))\n",
    "\n",
    "with open('afterCountVectorizer.txt', 'w') as f:\n",
    "    # f.write(str(word_count_dict))\n",
    "    f.write(str(vectorizer.get_feature_names_out().tolist()))\n",
    "\n",
    "\n",
    "# with open('output.txt', 'r') as f:\n",
    "#     print(f.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(vectorizer.get_feature_names_out()[703])\n",
    "#print(review_list)\n",
    "# print(vectorizer.get_feature_names_out()[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'oh': 590, 'mention': 548, 'weird': 965, 'color': 160, 'phone': 628, 'didn': 223, 'work': 981, 'waste': 952, '13': 3, 'bucks': 100, 'product': 677, 'useless': 923, 'does': 241, 'charging': 131, 'charge': 128, 'use': 921, 'headset': 398, 'stay': 819, 'ears': 262, 'worst': 987, 'customer': 195, 'service': 773, 'lacking': 477, 'makes': 529, 'sound': 800, 'says': 747, 'signal': 786, 'failed': 303, 'disappointing': 234, 'thing': 873, 'disappointed': 233, 'basically': 60, 'bad': 54, 'choice': 146, 'red': 710, 'horrible': 423, 'times': 882, 'feels': 323, 'poorly': 656, 'constructed': 176, 'difficult': 225, 'buttons': 108, 'don': 244, 'make': 528, 'mistake': 557, 'did': 222, 'low': 525, 'quality': 686, 'super': 844, 'advise': 20, 'doesn': 242, 'hold': 414, 'time': 881, 'decision': 209, 'like': 499, 'felt': 324, 'bought': 88, 'bluetooth': 82, 'fit': 331, 'better': 75, 'things': 874, 'wear': 961, 'tried': 899, 'months': 562, 'pros': 679, 'recommend': 708, '50': 7, 'drain': 249, 'junk': 467, 'store': 829, 'item': 458, 'big': 76, 'disappointment': 235, 'impressed': 439, 'just': 468, 'charged': 129, 'went': 966, 'turned': 906, 'blue': 81, '20': 4, 'left': 490, 'plus': 652, 'seriously': 769, 'believe': 71, 'worth': 988, 'price': 670, 'point': 654, 'house': 428, 'getting': 363, 'dropped': 255, 'hours': 427, 'literally': 505, 'unreliable': 918, 'mobile': 558, 'weak': 960, 'simple': 788, 'little': 506, 'pretty': 668, 'piece': 632, 'try': 903, 'ear': 257, 'plug': 651, 'unfortunately': 915, 'ability': 10, 'actually': 17, 'know': 474, 'important': 438, 'feature': 319, 'pitiful': 633, 've': 929, 'looking': 515, 'good': 377, 'motorola': 564, 'isn': 456, 'battery': 62, 'year': 997, 'completely': 170, 'dead': 205, 'crap': 189, 'poor': 655, 'construction': 177, 'weeks': 964, 'break': 91, 'strong': 834, 'really': 701, 'wanted': 947, 'plantronics': 641, '510': 8, 'right': 724, 'excellent': 291, 'awful': 52, 'end': 276, 'design': 216, 'having': 395, 'camera': 115, 'nokia': 581, 'looks': 516, 'picture': 630, 'case': 118, 'huge': 429, 'comfortable': 164, 'way': 958, 'fits': 332, 'wrong': 995, 'new': 578, 'bar': 56, 'starts': 817, 'letting': 492, 'stupid': 836, 'buying': 110, 'car': 116, 'headphones': 397, 'comes': 162, 'bit': 78, 'real': 700, 'loud': 520, 'gets': 362, 'old': 592, 'told': 885, 'wasn': 951, 'great': 381, 'calls': 113, 'odd': 588, 'clip': 157, 'thought': 877, 'deal': 206, 'razr': 697, 'dont': 245, 'buy': 109, 'unless': 917, 'sucks': 842, 'long': 512, 'waiting': 942, 'sure': 848, 'think': 875, 'plan': 640, 'problem': 675, 'easily': 265, 'line': 502, 'worthless': 989, 'cheap': 134, 'sprint': 810, 'pair': 607, 'wise': 973, 'clear': 153, 'talk': 858, 'purchase': 683, 'worked': 982, 'look': 513, 'cool': 182, 'charger': 130, 'broke': 97, 'soon': 799, 'likes': 501, 'slow': 792, 'say': 745, 'sending': 766, 'came': 114, 'verizon': 932, 'cell': 123, 'phones': 629, 'giving': 368, 'got': 378, 'breaking': 93, 'despite': 217, 'care': 117, 'money': 561, 'forced': 341, 'stop': 827, 'using': 924, 'checked': 136, 'll': 509, 'earpiece': 261, 'couldn': 185, 'software': 794, 'used': 922, 'zero': 1001, 'stars': 815, 'day': 203, 'mother': 563, 'volume': 938, 'check': 135, 'voice': 937, 'night': 580, 'turns': 907, 'lost': 517, 'week': 963, 'started': 816, 'probably': 674, 'changing': 125, 'pay': 618, 'guess': 384, 'kind': 473, 'child': 142, 'company': 167, 'expected': 294, 'experience': 295, 'feel': 321, 'days': 204, 'happened': 391, 'unit': 916, 'interested': 451, 'bt': 99, 'tell': 864, 'working': 983, 'earbud': 258, 'breaks': 94, 'barely': 57, 'hear': 401, 'saying': 746, 'ordered': 595, 'immediately': 437, 'shipping': 779, 'extra': 297, 'later': 484, 'scratched': 752, 'problems': 676, 'reading': 698, 'turn': 905, 'plastic': 642, 'whatsoever': 967, 'people': 620, 'player': 645, 'fry': 352, 'return': 720, 'computer': 171, 'bother': 87, 'form': 343, 'uncomfortable': 912, 'send': 765, 'expect': 293, 'screen': 753, 'goes': 373, 'black': 79, 'genuine': 361, 'come': 161, 'belt': 73, 'kept': 469, 'cable': 111, 'seat': 757, 'pull': 682, 'trash': 894, 'hate': 394, 'set': 774, 'managed': 532, 'place': 636, 'rated': 695, 'impressive': 440, 'fall': 306, 'high': 407, 'face': 301, 'match': 537, 'tool': 888, 'away': 50, 'sucked': 841, 'stuff': 835, 'minutes': 555, 'pictures': 631, 'headsets': 399, 'quite': 689, 'previous': 669, 'lg': 494, 'provided': 680, 'instructions': 447, 'cover': 188, 'light': 496, 'appealing': 30, 'wonder': 976, 'particular': 612, 'clearly': 154, 'gotten': 379, 'forget': 342, 'bars': 59, 'home': 418, 'life': 495, 'internet': 453, 'fine': 329, 'rare': 693, 'audio': 46, 'missed': 556, 'reason': 702, 'received': 705, 'reception': 707, 'truly': 902, 'earlier': 259, 'review': 721, 'going': 374, '12': 2, 'connection': 173, 'warning': 950, 'performance': 623, 'want': 946, 'holster': 417, 'understand': 914, 'pricing': 673, 'chinese': 144, 'lasts': 482, 'wife': 969, 'mind': 553, 'gonna': 376, 'disgusting': 237, 'need': 574, 'book': 83, 'short': 780, 'small': 793, 'avoid': 49, 'supposedly': 847, 'obviously': 586, 'series': 768, 'fairly': 305, 'trouble': 900, 'person': 625, 'support': 846, 'walked': 944, 'ended': 277, 'hard': 393, 'data': 201, 'white': 968, 'couple': 186, 'original': 597, 'ok': 591, 'totally': 891, 'word': 979, 'said': 734, 'replace': 716, 'flaw': 336, 'device': 219, 'area': 34, 'trying': 904, 'website': 962, 'given': 366, 'star': 814, 'able': 11, 'needed': 575, 'years': 998, 'moving': 568, 'killer': 472, 'course': 187, 'addition': 18, 'lightweight': 498, 'sitting': 791, 'recently': 706, '10': 0, 'garbage': 357, 'replacement': 717, 'arrived': 36, 'terrible': 866, 'easy': 266, 'best': 74, 'games': 356, 'ready': 699, 'coming': 166, 'wind': 970, 'pocket': 653, 'usb': 920, 'quickly': 688, 'holds': 415, 'lot': 518, 'simply': 789, 'highly': 408, 'wouldn': 991, 'fun': 353, 'sony': 798, 'thats': 871, 'mediocre': 544, 'inexpensive': 444, 'cingular': 149, 'decent': 208, 'places': 638, 'happy': 392, 'placed': 637, 'treo': 898, 'room': 729, 'sides': 785, 'touch': 892, 'music': 570, 'hands': 390, 'amazon': 25, 'extremely': 298, 'hot': 425, 'dirty': 232, 'helpful': 406, 'different': 224, 'share': 778, 'play': 643, 'clarity': 150, 'large': 481, 'falling': 307, 'save': 743, 'costs': 184, 'far': 312, 'ease': 263, 'date': 202, 'means': 542, 'note': 583, 'appearance': 31, 'bland': 80, 'especially': 288, 'continue': 178, 'pairing': 608, 'iphone': 455, 'multiple': 569, 'wall': 945, 'easier': 264, 'hit': 412, 'mic': 551, 'son': 796, 'nearly': 573, 'stopped': 828, 'free': 344, 'cute': 197, 'loads': 510, 'works': 984, 'superb': 845, 'run': 731, 'recommended': 709, 'amazed': 23, 'finally': 328, 'definitely': 210, 'bargain': 58, 'family': 308, 'overall': 601, 'jawbone': 461, 'era': 287, 'awesome': 51, 'incredible': 442, 'value': 927, 'offers': 589, 'options': 593, 'needs': 576, 'glad': 369, 'priced': 671, 'won': 975, 'fantastic': 311, 'perfectly': 622, 'cases': 119, 'quick': 687, 'charm': 132, 'ago': 22, 'love': 521, 'sturdy': 837, 'leather': 487, 'nice': 579, 'cut': 196, 'amazing': 24, 'type': 910, 'setup': 777, 'edge': 270, 'instead': 446, 'inside': 445, 'convenient': 180, 'job': 462, 'features': 320, 'pc': 619, 'crisp': 193, 'comfortably': 165, 'authentic': 47, 'comfort': 163, 'video': 934, 'rocks': 725, 'loves': 524, 'doing': 243, 'hand': 388, 'jabra': 459, 'pleased': 649, 'ask': 38, 'friends': 349, 'enjoy': 280, 'adorable': 19, 'owned': 603, 'satisfied': 741, 'appears': 32, 'let': 491, 'keyboard': 470, 'number': 584, 'exactly': 290, 'samsung': 737, 'strip': 833, 'im': 435, 'solid': 795, 'absolutely': 12, 'station': 818, 'worthwhile': 990, 'roles': 727, 'wonderfully': 978, 'range': 691, 'generally': 359, 'glasses': 371, 'regret': 711, 'total': 890, 'certainly': 124, 'clever': 155, 'help': 405, 'fast': 313, 'orders': 596, 'order': 594, 'gave': 358, 'beautiful': 65, 'seller': 764, 'eye': 299, 'thanks': 870, 'passed': 614, 'mark': 535, '100': 1, 'beat': 64, 'occupied': 587, 'loved': 522, 'hour': 426, 'tv': 908, 'reasonably': 704, 'effective': 272, 'entire': 284, 'tiny': 883, 'thumbs': 880, 'brilliant': 95, 'tremendous': 897, 'graphics': 380, 'incredibly': 443, 'driving': 254, 'living': 508, 'took': 887, 'making': 530, 'favorite': 316, 'self': 763, 'outside': 599, 'control': 179, 'joy': 465, 'boot': 84, 'boy': 89, 'reasonable': 703, 'setting': 776, 'rating': 696, 'mess': 550, 'hair': 386, 'shots': 782, 'effects': 273, 'complaints': 168, 'friendly': 348, 'effort': 274, 'world': 985, 'fact': 302, 'wish': 974, 'negative': 577, 'values': 928, 'casting': 121, 'cause': 122, 'actors': 16, 'scenes': 751, 'green': 383, 'seen': 761, 'game': 355, 'boring': 86, 'horror': 424, 'movies': 567, '90': 9, 'atmosphere': 41, 'lame': 480, 'premise': 665, 'film': 325, 'ridiculous': 723, 'watch': 954, 'watchable': 955, 'human': 430, 'plot': 650, 'watched': 956, 'glance': 370, 'cost': 183, 'saw': 744, 'theater': 872, 'sick': 784, 'laughable': 485, 'predictable': 664, 'idea': 434, 'character': 126, 'pg': 626, 'complete': 169, 'non': 582, 'movie': 566, 'characters': 127, 'drama': 250, 'actor': 15, 'playing': 646, 'rent': 715, 'fails': 304, 'pure': 684, 'disaster': 236, 'story': 831, 'editing': 271, 'wow': 992, 'lines': 503, 'second': 759, 'pleasant': 648, 'plain': 639, 'bakery': 55, 'waitress': 943, 'wasted': 953, 'scene': 749, 'mouth': 565, 'kids': 471, 'script': 755, 'final': 327, 'torture': 889, 'ending': 278, 'directing': 229, 'pretentious': 667, 'funny': 354, 'considering': 175, 'summary': 843, 'lacks': 478, 'visual': 936, 'feeling': 322, 'narrative': 571, 'doubt': 247, 'half': 387, 'bunch': 103, 'worse': 986, 'acting': 13, 'stanwyck': 813, 'usual': 925, 'hitchcock': 413, 'plays': 647, 'lacked': 476, 'depth': 214, 'utterly': 926, 'level': 493, 'films': 326, 'annoying': 28, 'storyline': 832, 'insult': 448, 'intelligence': 449, 'budget': 101, 'action': 14, 'frightening': 351, 'seeing': 760, 'minute': 554, 'unconvincing': 913, 'sets': 775, 'episode': 285, 'dialogue': 221, 'sense': 767, 'young': 999, 'man': 531, 'stories': 830, 'unbelievable': 911, 'particularly': 613, 'memories': 547, 'watching': 957, 'written': 994, 'surprisingly': 849, 'directed': 228, 'fat': 314, 'girl': 365, 'shot': 781, 'space': 803, 'direction': 230, 'mean': 540, 'yeah': 996, 'pathetic': 617, 'bored': 85, 'damn': 198, 'conclusion': 172, 'average': 48, 'remember': 714, 'meaning': 541, 'handled': 389, 'imagination': 436, 'paid': 606, 'documentary': 240, '30': 5, 'words': 980, 'chemistry': 139, 'consider': 174, 'leave': 488, 'oscar': 598, 'cast': 120, 'fish': 330, 'lead': 486, 'eyes': 300, 'suspense': 851, 'aren': 35, 'business': 106, 'believable': 70, 'screenwriter': 754, 'released': 712, 'special': 805, 'heard': 402, 'looked': 514, 'bring': 96, 'gives': 367, 'created': 192, 'maybe': 538, 'talented': 857, 'director': 231, 'head': 396, 'spent': 807, 'rate': 694, 'stinks': 825, 'stayed': 820, 'giallo': 364, 'sub': 839, 'thrown': 879, 'writing': 993, 'reviews': 722, 'god': 372, 'drive': 253, 'james': 460, 'fan': 309, 'songs': 797, 'close': 158, 'ups': 919, 'hell': 404, 'scale': 748, 'past': 615, 'master': 536, 'follow': 339, 'main': 527, 'involved': 454, 'production': 678, 'putting': 685, 'style': 838, 'speak': 804, 'flick': 337, 'presents': 666, 'lots': 519, 'clichés': 156, 'rolls': 728, 'john': 463, 'death': 207, 'paper': 609, 'holes': 416, 'guy': 385, 'moment': 560, 'joke': 464, 'flat': 333, 'attention': 43, 'gone': 375, 'belly': 72, 'dance': 199, 'rest': 718, 'billy': 77, 'remake': 713, 'energy': 279, 'spend': 806, 'age': 21, 'drago': 248, 'dialog': 220, 'early': 260, 'possible': 660, 'honestly': 421, 'today': 884, 'pace': 604, 'single': 790, 'performances': 624, 'twice': 909, 'art': 37, 'intelligent': 450, 'attempt': 42, 'race': 690, 'dry': 256, 'list': 504, 'cinematography': 148, 'lighting': 497, 'audience': 45, 'fear': 318, 'delivers': 213, 'soundtrack': 801, 'cinema': 147, 'wonderful': 977, 'interesting': 452, 'beginning': 69, 'spot': 809, 'fans': 310, 'south': 802, 'memorable': 546, 'running': 732, 'liked': 500, 'paced': 605, 'classic': 151, '40': 6, 'terrific': 867, 'including': 441, 'hip': 410, 'perfect': 621, 'enjoyed': 282, 'fresh': 345, 'entertaining': 283, 'steve': 824, 'lovely': 523, 'thriller': 878, 'nasty': 572, 'hilarious': 409, 'scenery': 750, 'history': 411, 'role': 726, 'played': 644, 'charming': 133, 'beautifully': 66, 'portrayal': 659, 'subtle': 840, 'exquisite': 296, 'ways': 959, 'modern': 559, 'possibly': 661, 'huston': 432, 'favourite': 317, 'greatest': 382, 'enjoyable': 281, 'deserves': 215, 'exceptional': 292, 'known': 475, 'parents': 611, 'provoking': 681, 'ranks': 692, 'mickey': 552, 'appreciate': 33, 'crowd': 194, 'tom': 886, 'heart': 403, 'checking': 137, 'lady': 479, 'taste': 859, 'children': 143, 'judge': 466, 'leaves': 489, 'hope': 422, 'war': 948, 'thoroughly': 876, 'step': 823, 'nut': 585, 'buffet': 102, 'italian': 457, 'sat': 740, 'sad': 733, 'sweet': 852, 'tale': 856, 'late': 483, 'faux': 315, 'silent': 787, 'vibe': 933, 'served': 770, 'true': 901, 'crazy': 190, 'treat': 895, 'cold': 159, 'dark': 200, 'location': 511, 'rude': 730, 'bathroom': 61, 'eat': 267, 'food': 340, 'tables': 854, 'restaurant': 719, 'warm': 949, 'chicken': 141, 'wings': 972, 'meat': 543, 'eaten': 268, 'ambiance': 26, 'tea': 863, 'flavor': 334, 'texture': 868, 'servers': 772, 'shrimp': 783, 'fried': 346, 'salad': 735, 'stale': 812, 'live': 507, 'steak': 821, 'chewy': 140, 'selection': 762, 'vegas': 930, 'staff': 811, 'brunch': 98, 'par': 610, 'wait': 939, 'server': 771, 'dish': 238, 'husband': 431, 'cafe': 112, 'drinks': 252, 'sauce': 742, 'spicy': 808, 'eating': 269, 'burger': 104, 'pizza': 634, 'door': 246, 'manager': 534, 'anytime': 29, 'treated': 896, 'tasted': 860, 'burgers': 105, 'cooked': 181, 'sashimi': 739, 'tasteless': 861, 'sushi': 850, 'cream': 191, 'vegetables': 931, 'establishment': 289, 'clean': 152, 'asked': 39, 'beer': 68, 'friend': 347, 'pasta': 616, 'stomach': 826, 'wine': 971, 'pho': 627, 'dishes': 239, 'thai': 869, 'waited': 940, 'seated': 758, 'folks': 338, 'potatoes': 663, 'overpriced': 602, 'table': 853, 'attentive': 44, 'ate': 40, 'potato': 662, 'chips': 145, 'tasty': 862, 'lunch': 526, 'seafood': 756, 'equally': 286, 'pizzas': 635, 'management': 533, 'prices': 672, 'portions': 658, 'waiter': 941, 'fries': 350, 'beef': 67, 'busy': 107, 'beans': 63, 'dining': 226, 'honest': 420, 'menu': 549, 'breakfast': 92, 'salmon': 736, 'meal': 539, 'dinner': 227, 'egg': 275, 'ice': 433, 'tacos': 855, 'pork': 657, 'dessert': 218, 'sandwich': 738, 'visit': 935, 'yummy': 1000, 'steaks': 822, 'bread': 90, 'delicious': 211, 'bacon': 53, 'tender': 865, 'chef': 138, 'generous': 360, 'drink': 251, 'melt': 545, 'homemade': 419, 'flavorful': 335, 'ambience': 27, 'healthy': 400, 'delish': 212, 'outstanding': 600, 'town': 893}\n"
     ]
    }
   ],
   "source": [
    "#sorted_tokens = list(sorted(vectorizer.vocabulary_, key=word_count_dict.get, reverse=True))\n",
    "\n",
    "#print(type(sorted_tokens)) # list of tokens sorted by frequency\n",
    "\n",
    "# Print all words in list and their frequencies from the dictionary\n",
    "#for w in sorted_tokens:\n",
    "#    print(\"%5d %s\" % (word_count_dict[w], w))\n",
    "    \n",
    "# Create a dictionary of the sorted tokens list\n",
    "#vocab_dict = create_dict(sorted_tokens)\n",
    "print(vectorizer.vocabulary_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWords = ['the', 'a', 'and', 'of', 'to', 'is', 'it', 'in', 'i', 'this']\n",
    "count_V = make_feature_vector(sorted_tokens, vocab_dict)\n",
    "\n",
    "print(count_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 1002)\n"
     ]
    }
   ],
   "source": [
    "# Turning reviews into feature vectors\n",
    "N = len(review_list)\n",
    "V = len(vectorizer.vocabulary_)\n",
    "\n",
    "x_tr_NV = np.zeros((N,V))   # N x V matrix of feature vectors\n",
    "\n",
    "\n",
    "for nn, review_line in enumerate(review_list):\n",
    "    x_tr_NV[nn] = make_feature_vector(review_line, vectorizer.vocabulary_)\n",
    "# TODO are we using the right inputs and functions here?\n",
    "print(x_tr_NV.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn.model_selection.RandomizedSearchCV\n",
    "Look for if there is an industry standard for what % of your training data should be the number of iterations and just use that and explain that's what you considered instead of evaluating that you have reached an optimum minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a random search cross validation to generate optimum C, penalty and max_iter for a logistic regression classifier\n",
    "logistic = sklm.LogisticRegression(solver='liblinear', max_iter=300)\n",
    "distributions = dict(C=np.logspace(-9,-6,100),penalty = ['l2', 'l1'])\n",
    "randClassifier = skms.RandomizedSearchCV(logistic, distributions, n_iter=100, cv=None, verbose=0, random_state=0, \n",
    "                                         error_score='raise', return_train_score=True)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Tried to add shuffle before passing it into the randomizedSearchCV to see if it would improve the fit. It basically didn't - tiny improvement.\n",
    "x_tr_NV, rating_list = shuffle(x_tr_NV, rating_list, random_state=0)\n",
    "\n",
    "randClassifier.fit(x_tr_NV, rating_list)\n",
    "# TODO ensure we're passing the right x and y variables and that they match each other (right ratings with each review) into the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just experimenting to ensure that if I pass 2 arrays in that shuffle shuffles both in the same way\n",
    "# a = np.arange(18)\n",
    "# b = np.arange(18)+7\n",
    "\n",
    "# a, b = shuffle(a, b, random_state=0)\n",
    "\n",
    "# print(a)\n",
    "# print(b-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of 0 and 1 [2400,2]\n",
    "yhat = randClassifier.predict_proba(x_tr_NV)\n",
    "print(type(yhat))\n",
    "with open('yhat.txt', 'w') as f:\n",
    "    f.write(str(yhat.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the AUROC accuracy of the classifier on the training data\n",
    "acc = roc_auc_score(rating_list, yhat[:, 1])\n",
    "print(\"Training accuracy: %.3f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_feature_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_iris\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from scipy.stats import uniform\n",
    "# iris = load_iris()\n",
    "# logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200, random_state=0)\n",
    "# distributions = dict(C=uniform(loc=0, scale=4), penalty=['l2', 'l1'])\n",
    "# clf = RandomizedSearchCV(logistic, distributions, random_state=0)\n",
    "# search = clf.fit(iris.data, iris.target)\n",
    "# search.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
